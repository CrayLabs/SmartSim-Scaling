{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "\n",
    "\n",
    "palette = sns.set_palette(\"colorblind\", color_codes=True)\n",
    "\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "matplotlib.rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hashableDict(dict):\n",
    "    def __hash__(self):\n",
    "        return hash(tuple(sorted(self.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results'\n",
    "scaling_test = 'inference-colocated-scaling'\n",
    "run_path = 'run-2023-06-13-16:08:40'\n",
    "full_path = Path(results_path, scaling_test, run_path)\n",
    "\n",
    "configs = []\n",
    "\n",
    "for run_cfg in Path(full_path).rglob('run.cfg'):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(run_cfg)\n",
    "    configs.append(config)\n",
    "df_list = []\n",
    "for config in configs:\n",
    "    timing_files = Path(config['run']['path']).glob('rank*.csv')\n",
    "    for timing_file in timing_files:\n",
    "        tmp_df = pd.read_csv(timing_file, header=0, names=[\"rank\", \"function\", \"time\"])\n",
    "        for key, value in config._sections['attributes'].items():\n",
    "            tmp_df[key] = value\n",
    "        df_list.append(tmp_df)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>function</th>\n",
       "      <th>time</th>\n",
       "      <th>colocated</th>\n",
       "      <th>pin_app_cpus</th>\n",
       "      <th>client_total</th>\n",
       "      <th>client_per_node</th>\n",
       "      <th>client_nodes</th>\n",
       "      <th>database_nodes</th>\n",
       "      <th>database_cpus</th>\n",
       "      <th>database_threads_per_queue</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>device</th>\n",
       "      <th>num_devices</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.006576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>loop_time</td>\n",
       "      <td>1.508950</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>main()</td>\n",
       "      <td>18.614700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>put_tensor</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>run_script</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>run_model</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>unpack_tensor</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>loop_time</td>\n",
       "      <td>1.454070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>main()</td>\n",
       "      <td>18.620300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank       function       time colocated pin_app_cpus client_total  \\\n",
       "0      0     put_tensor   0.000661         1            0            2   \n",
       "1      0     run_script   0.001220         1            0            2   \n",
       "2      0      run_model   0.006576         1            0            2   \n",
       "3      0  unpack_tensor   0.000116         1            0            2   \n",
       "4      0     put_tensor   0.000619         1            0            2   \n",
       "5      0     run_script   0.001357         1            0            2   \n",
       "6      0      run_model   0.006349         1            0            2   \n",
       "7      0  unpack_tensor   0.000112         1            0            2   \n",
       "8      0     put_tensor   0.000681         1            0            2   \n",
       "9      0     run_script   0.001210         1            0            2   \n",
       "10     0      run_model   0.006529         1            0            2   \n",
       "11     0  unpack_tensor   0.000117         1            0            2   \n",
       "12     0     put_tensor   0.000695         1            0            2   \n",
       "13     0     run_script   0.001291         1            0            2   \n",
       "14     0      run_model   0.006641         1            0            2   \n",
       "15     0  unpack_tensor   0.000113         1            0            2   \n",
       "16     0      loop_time   1.508950         1            0            2   \n",
       "17     0         main()  18.614700         1            0            2   \n",
       "18     1     put_tensor   0.001037         1            0            2   \n",
       "19     1     run_script   0.001586         1            0            2   \n",
       "20     1      run_model   0.011525         1            0            2   \n",
       "21     1  unpack_tensor   0.000130         1            0            2   \n",
       "22     1     put_tensor   0.001002         1            0            2   \n",
       "23     1     run_script   0.001710         1            0            2   \n",
       "24     1      run_model   0.011447         1            0            2   \n",
       "25     1  unpack_tensor   0.000127         1            0            2   \n",
       "26     1     put_tensor   0.001018         1            0            2   \n",
       "27     1     run_script   0.001703         1            0            2   \n",
       "28     1      run_model   0.011412         1            0            2   \n",
       "29     1  unpack_tensor   0.000140         1            0            2   \n",
       "30     1     put_tensor   0.001066         1            0            2   \n",
       "31     1     run_script   0.001679         1            0            2   \n",
       "32     1      run_model   0.011626         1            0            2   \n",
       "33     1  unpack_tensor   0.000132         1            0            2   \n",
       "34     1      loop_time   1.454070         1            0            2   \n",
       "35     1         main()  18.620300         1            0            2   \n",
       "\n",
       "   client_per_node client_nodes database_nodes database_cpus  \\\n",
       "0                2            1              1             2   \n",
       "1                2            1              1             2   \n",
       "2                2            1              1             2   \n",
       "3                2            1              1             2   \n",
       "4                2            1              1             2   \n",
       "5                2            1              1             2   \n",
       "6                2            1              1             2   \n",
       "7                2            1              1             2   \n",
       "8                2            1              1             2   \n",
       "9                2            1              1             2   \n",
       "10               2            1              1             2   \n",
       "11               2            1              1             2   \n",
       "12               2            1              1             2   \n",
       "13               2            1              1             2   \n",
       "14               2            1              1             2   \n",
       "15               2            1              1             2   \n",
       "16               2            1              1             2   \n",
       "17               2            1              1             2   \n",
       "18               2            1              1             2   \n",
       "19               2            1              1             2   \n",
       "20               2            1              1             2   \n",
       "21               2            1              1             2   \n",
       "22               2            1              1             2   \n",
       "23               2            1              1             2   \n",
       "24               2            1              1             2   \n",
       "25               2            1              1             2   \n",
       "26               2            1              1             2   \n",
       "27               2            1              1             2   \n",
       "28               2            1              1             2   \n",
       "29               2            1              1             2   \n",
       "30               2            1              1             2   \n",
       "31               2            1              1             2   \n",
       "32               2            1              1             2   \n",
       "33               2            1              1             2   \n",
       "34               2            1              1             2   \n",
       "35               2            1              1             2   \n",
       "\n",
       "   database_threads_per_queue batch_size device num_devices language  \n",
       "0                           1         96    GPU           1      cpp  \n",
       "1                           1         96    GPU           1      cpp  \n",
       "2                           1         96    GPU           1      cpp  \n",
       "3                           1         96    GPU           1      cpp  \n",
       "4                           1         96    GPU           1      cpp  \n",
       "5                           1         96    GPU           1      cpp  \n",
       "6                           1         96    GPU           1      cpp  \n",
       "7                           1         96    GPU           1      cpp  \n",
       "8                           1         96    GPU           1      cpp  \n",
       "9                           1         96    GPU           1      cpp  \n",
       "10                          1         96    GPU           1      cpp  \n",
       "11                          1         96    GPU           1      cpp  \n",
       "12                          1         96    GPU           1      cpp  \n",
       "13                          1         96    GPU           1      cpp  \n",
       "14                          1         96    GPU           1      cpp  \n",
       "15                          1         96    GPU           1      cpp  \n",
       "16                          1         96    GPU           1      cpp  \n",
       "17                          1         96    GPU           1      cpp  \n",
       "18                          1         96    GPU           1      cpp  \n",
       "19                          1         96    GPU           1      cpp  \n",
       "20                          1         96    GPU           1      cpp  \n",
       "21                          1         96    GPU           1      cpp  \n",
       "22                          1         96    GPU           1      cpp  \n",
       "23                          1         96    GPU           1      cpp  \n",
       "24                          1         96    GPU           1      cpp  \n",
       "25                          1         96    GPU           1      cpp  \n",
       "26                          1         96    GPU           1      cpp  \n",
       "27                          1         96    GPU           1      cpp  \n",
       "28                          1         96    GPU           1      cpp  \n",
       "29                          1         96    GPU           1      cpp  \n",
       "30                          1         96    GPU           1      cpp  \n",
       "31                          1         96    GPU           1      cpp  \n",
       "32                          1         96    GPU           1      cpp  \n",
       "33                          1         96    GPU           1      cpp  \n",
       "34                          1         96    GPU           1      cpp  \n",
       "35                          1         96    GPU           1      cpp  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'put_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i, language \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(languages):\n\u001b[1;32m     17\u001b[0m     language_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_group(language)\n\u001b[0;32m---> 18\u001b[0m     function_df \u001b[39m=\u001b[39m language_df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mfunction\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mget_group(function_name)[ [\u001b[39m'\u001b[39m\u001b[39mclient_total\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] ]\n\u001b[1;32m     19\u001b[0m     data \u001b[39m=\u001b[39m [function_df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mclient_total\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_group(client)[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m ordered_client_total]\n\u001b[1;32m     20\u001b[0m     pos \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(client) \u001b[39mfor\u001b[39;00m client \u001b[39min\u001b[39;00m ordered_client_total]\n",
      "File \u001b[0;32m/lus/scratch/richaama/miniconda3/envs/plz3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:817\u001b[0m, in \u001b[0;36mBaseGroupBy.get_group\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    815\u001b[0m inds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_index(name)\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(inds):\n\u001b[0;32m--> 817\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(name)\n\u001b[1;32m    819\u001b[0m \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'put_tensor'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "violin_opts = dict(        \n",
    "    showmeans = True,\n",
    "    showextrema = True,        \n",
    ")\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "ordered_client_total = sorted(df['client_total'].unique())\n",
    "\n",
    "function_names = df['function'].drop_duplicates().tolist()\n",
    "languages = ['cpp']\n",
    "\n",
    "for function_name in function_names:\n",
    "    fig = plt.figure(figsize=[12,4])\n",
    "    axs = fig.subplots(1,2,sharey=True)\n",
    "    for i, language in enumerate(languages):\n",
    "        language_df = df.groupby('language').get_group(language)\n",
    "        function_df = language_df.groupby('function').get_group(function_name)[ ['client_total','time'] ]\n",
    "        data = [function_df.groupby('client_total').get_group(client)['time'] for client in ordered_client_total]\n",
    "        pos = [int(client) for client in ordered_client_total]\n",
    "        axs[i].violinplot(data, pos, **violin_opts, widths=24)\n",
    "        axs[i].set_xlabel('Number of Clients')\n",
    "        axs[i].set_title(language)\n",
    "        axs[i].set_xticks(pos)\n",
    "    axs[0].set_ylabel(f'{function_name}\\nTime (s)')\n",
    "# plt.box(put_tensor_df['client_total'], put_tensor_df['time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '24', '36', '60', '96']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Fortran and C++\n",
    "\n",
    "for key, value in run_data:\n",
    "    value['client_total'] = \n",
    "\n",
    "\n",
    "fortran_dfs = {hashed_config:run_data[hashed_config] for hashed_config in hashed_configs if hashed_config['language']=='fortran'}\n",
    "cpp_dfs = {hashed_config:run_data[hashed_config] for hashed_config in hashed_configs if hashed_config['language']=='cpp'}\n",
    "\n",
    "fields = [\"put_tensor\", \"run_model\", \"unpack_tensor\"]\n",
    "\n",
    "\n",
    "\n",
    "# for field in fields:\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[0]\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for timing_file in timing_files:\n",
    "    df_list.append(pd.read_csv(timing_file, header=0, names=[\"rank\", \"function\", \"time\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('function').get_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = [12,24,48,96]\n",
    "n_nodes = [1]\n",
    "DB_cpus = 12\n",
    "db_tpq = 2\n",
    "\n",
    "aggregate = False\n",
    "\n",
    "df_dbs = dict()\n",
    "infer_path = '../results/inference-colocated-scaling'\n",
    "run_paths = glob(os.path.join(infer_path,'run-2023*'))\n",
    "\n",
    "functions = ['put_tensor', 'run_script', 'run_model', 'unpack_tensor']\n",
    "\n",
    "dfs = { path:dict() for path in run_paths }\n",
    "\n",
    "for run_path in run_paths:\n",
    "    base_path = run_path \n",
    "    for n_node in n_nodes:\n",
    "\n",
    "        for n_client in n_clients: \n",
    "            path_roots = os.path.join(base_path, f'infer-sess-colo-N{n_node}-T{n_client}-DBN1-DBCPU{DB_cpus}-DBTPQ{db_tpq}-*')\n",
    "            for path_root in path_roots:\n",
    "            path = glob(path_root)[0]\n",
    "            files = os.listdir(path)\n",
    "            \n",
    "            function_times = {}\n",
    "\n",
    "            for file in files:\n",
    "                if '.csv' in file and 'rank_' in file:\n",
    "                    fp = os.path.join(path, file)\n",
    "                    function_rank_times = {}\n",
    "                    with open(fp) as f:\n",
    "                        for i, line in enumerate(f):\n",
    "                            vals = line.split(',')\n",
    "                            if vals[1] not in functions:\n",
    "                                continue\n",
    "                            if not aggregate:\n",
    "                                if vals[1] in function_times.keys():\n",
    "                                    function_times[vals[1]].append(float(vals[2]))\n",
    "                                else:\n",
    "                                    function_times[vals[1]] = [float(vals[2])]\n",
    "                            else:\n",
    "                                if vals[1] in function_rank_times.keys():\n",
    "                                    function_rank_times[vals[1]] += float(vals[2])\n",
    "                                else:\n",
    "                                    function_rank_times[vals[1]] = float(vals[2])\n",
    "                                \n",
    "                    for k,v in function_rank_times.items():\n",
    "                        if k in function_times:\n",
    "                            function_times[k].append(v)\n",
    "                        else:\n",
    "                            function_times[k] = [v]\n",
    "                \n",
    "            data_df = pd.DataFrame(function_times)\n",
    "            dfs[run_path][n_client] = data_df\n",
    "\n",
    "        labels = [\"put_tensor\", \"unpack_tensor\", \"run_model\", \"run_script\"]\n",
    "        for n_client in n_clients:\n",
    "            dfs[run_path][n_client]['total'] = np.sum([dfs[run_path][n_client][label] for label in labels],axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_path in run_paths:\n",
    "    print(run_path)\n",
    "    print(dfs[run_path][96].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_path in run_paths:\n",
    "    print(run_path)\n",
    "    print(dfs[run_path][96].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "all_in_one = False\n",
    "labels = [\"put_tensor\", \"unpack_tensor\", \"run_model\", \"run_script\", \"total\"]\n",
    "palette = sns.set_palette(\"colorblind\", color_codes=True)\n",
    "\n",
    "\n",
    "dfs_plot = dfs[run_paths[1]]\n",
    "\n",
    "for style in tqdm([\"light\", \"dark\"], desc=\"Plotting\"):\n",
    "    if style == \"light\":\n",
    "        plt.style.use(\"default\")\n",
    "    else:\n",
    "        plt.style.use(\"dark_background\")\n",
    "\n",
    "    legend_entries = []\n",
    "\n",
    "    color_short = \"brgmy\"\n",
    "\n",
    "    aggregate_suffix = \"_agg\" if aggregate else \"\"\n",
    "    plot_type = \"violin\"\n",
    "\n",
    "    # Set subplot_index to None to plot to separate files, to 1 to have all plots in one\n",
    "    subplot_index = 1 if all_in_one else None\n",
    "    if subplot_index:\n",
    "        plt.figure(figsize=(8*2,5*2+3))\n",
    "    for label in tqdm(labels, desc=f\"{style} style\"):\n",
    "        if subplot_index:\n",
    "            ax = plt.subplot(2,2,subplot_index)\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "        data_list = [dfs_plot[n_client][label] for n_client in n_clients]\n",
    "        \n",
    "        if plot_type==\"violin\":\n",
    "            plot = ax.violinplot(data_list, positions=n_clients, showextrema=True, showmeans=True, showmedians=True ,widths=12)\n",
    "            [col.set_alpha(0.3) for col in plot[\"bodies\"]]\n",
    "            props_dict = dict(color=plot[\"cbars\"].get_color().flatten())\n",
    "            entry = plot[\"cbars\"]\n",
    "            legend_entries.append(entry)\n",
    "        means = [np.mean(dfs_plot[n_client][label]) for n_client in n_clients]\n",
    "        ax.plot(n_clients, means, ':', color=props_dict['color'], alpha=0.5)\n",
    "\n",
    "        \n",
    "        ax.set_xticks(n_clients, minor=False)\n",
    "        ax.set_xticklabels([rank for rank in n_clients], fontdict={'fontsize': 12})\n",
    "\n",
    "        plt.title(label)\n",
    "        plt.xlabel(\"MPI Ranks\")\n",
    "        plt.ylabel(\"Time [s]\")\n",
    "        # plt.ylim([0,0.06])\n",
    "        # ax.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%2.2f'))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.draw()\n",
    "\n",
    "        \n",
    "        if not subplot_index:\n",
    "            if save:\n",
    "                plt.savefig(f\"{label}_{plot_type}{aggregate_suffix}_{style}.pdf\")\n",
    "                plt.savefig(f\"{label}_{plot_type}{aggregate_suffix}_{style}.png\")\n",
    "        else:\n",
    "            subplot_index += 1\n",
    "\n",
    "    if subplot_index and save:\n",
    "        plt.savefig(f'all_in_one_{plot_type}{aggregate_suffix}_{style}.pdf')\n",
    "        plt.savefig(f'all_in_one_{plot_type}{aggregate_suffix}_{style}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.violinplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[96].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs[96].describe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.violinplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plz3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
